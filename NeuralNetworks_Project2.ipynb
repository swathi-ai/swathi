{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 64
    },
    "colab_type": "code",
    "id": "XRJVvG8rt87L",
    "outputId": "c0886f65-0113-4d9a-a42f-738d2eabe846"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8LOXhUCHuBvz",
    "outputId": "f9969854-f8f3-414f-a20b-00fcf0a9c400"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ESlhqSSHuKP1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KKJwFOHqTNTu"
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "eTTeEKCRuiHb",
    "outputId": "b993d33b-e891-4dcd-ac2c-ec0e3582f31f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "colab_type": "code",
    "id": "8ISZZ46dSPuG",
    "outputId": "3d2c4cfd-d6c6-4aee-9057-af8823ed2af4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of  X_test : \n",
      " (18000, 32, 32)\n",
      "shape of  X_train : \n",
      " (42000, 32, 32)\n",
      "shape of  X_val : \n",
      " (60000, 32, 32)\n",
      "shape of  y_test : \n",
      " (18000,)\n",
      "shape of  y_train : \n",
      " (42000,)\n",
      "shape of  y_val : \n",
      " (60000,)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('/gdrive/My Drive/Colab Notebooks/Neural Networks/Project2/SVHN_single_grey1-2.h5', 'r') as f:\n",
    "  ls = list(f.keys())\n",
    "  for dataset in ls:\n",
    "    data = f.get(dataset)\n",
    "    dataset1 = np.array(data)\n",
    "    print('shape of ', dataset,': \\n', dataset1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NEAn-48SWRbE"
   },
   "source": [
    "We have sufficient data for train, validation and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LypGGRFL3GI3"
   },
   "outputs": [],
   "source": [
    "data = h5py.File('/gdrive/My Drive/Colab Notebooks/Neural Networks/Project2/SVHN_single_grey1-2.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42rEeAGdI9ku"
   },
   "outputs": [],
   "source": [
    "X_train = np.array(data.get('X_train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "as7LSgz-Jui9",
    "outputId": "7a52994e-22e6-4aad-931d-b7bf22c4e5e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.array(data.get('y_train'))\n",
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aLFqkxVAAUvS"
   },
   "source": [
    "The images are of 32 x 32 shape and the target variable has 10 distinct values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k8k3TsXEV8A0"
   },
   "outputs": [],
   "source": [
    "X_val = np.array(data.get('X_val'))\n",
    "y_val = np.array(data.get('y_val'))\n",
    "X_test = np.array(data.get('X_test'))\n",
    "y_test = np.array(data.get('y_test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "54IQGw2gV76a"
   },
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_val = tf.keras.utils.to_categorical(y_val)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "colab_type": "code",
    "id": "36VWWC6ZKOKo",
    "outputId": "ed6931ea-f638-4e7f-8b4a-5f48a29ea50a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/matplotlib/text.py:1150: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if s != self._text:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEHCAYAAABoVTBwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmKsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEHCAYAAABoVTBwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAcT0lEQVR4nO2de5BV1ZXGv9XIQ3k00M2jgyigGEWc\noHRQ1AijpVEqFULFWFipxFIrJGOsmqQyfzimauKk5o/EmiSVqUzFkGiJUxp8G8r4YhiMGiOmRR4q\nIg0iD5uXvBVRmjV/3EOlIWd9fe/p7nvR/f2quvr2Xmefve6+Z/W5d393rW3uDiHEp5+6WjsghKgO\nCnYhEkHBLkQiKNiFSAQFuxCJoGAXIhFO6EpnM7sSwC8B9ALwO3f/CTu+vr7eR44cWWScivswSbHI\n+Vi/w4cPd+v5AKB3796hrU+fPoXOWYSi0myRfmwe6+ri+1KR+Wfz1N1zCPD5OHjwYMV9ovl49913\nsWvXrtwnUDjYzawXgP8GcDmATQD+amYL3P2NqM/IkSNxxx13VDxWdOGzyTh06FBoO+GE+Gn36tUr\ntEUTHL1YncEu4FGjRoW2U045JbRFz43NFQuW9vb20MaCosgF/PHHH4c29s/vww8/DG0Rffv2DW3s\ndSkKm8d169bltrPr6qSTTsptv/baa8M+XXlWUwC0uvs6d/8IwHwAM7twPiFED9KVYB8FYGOHvzdl\nbUKI45AeX6Azszlm1mJmLXv27Onp4YQQAV0J9s0ARnf4++Ss7Sjcfa67N7t7c319fReGE0J0ha4E\n+18BjDezsWbWB8BsAAu6xy0hRHdTeDXe3Q+Z2c0AnkZJervL3V8vo19uO1vZjVYy2aopW21lq8/M\nj8j3ojJfUTWhCEUlNOZHd0uiTAlhY5144omhLbpGiq7Gs/lgagJ73tH1zVSGyA+26t8lnd3dnwDw\nRFfOIYSoDvoGnRCJoGAXIhEU7EIkgoJdiERQsAuRCF1aja8Udw9lryLyFUuOKCp5MaJzFpENAZ7o\nwGSX999/P7T169cvt51JTUWlw48++ii0RTIae80YTJbbsWNHaNuwYUNuO5PQ9u/fH9r27dtXyI+2\ntraKx2Nj7d69O7d927ZtYR/d2YVIBAW7EImgYBciERTsQiSCgl2IRKjqaryZhUkGbLU1WtFmK93s\nfGxFmK0wR6uta9asCfusXr06tL333nuhja2ejxs3LrSde+65ue2f//znwz5jx44NbUWSTIB4hZ+t\ngjNVYO/evaFt3rx5oe2RRx4JbRHMR6aSFLUVSQ6LbExJ0J1diERQsAuRCAp2IRJBwS5EIijYhUgE\nBbsQiVB16S3auojJLpGNST+sHtj27dtD29KlS0Pb888/n9u+du3asA+rd8d8ZDz55JOhLargO2XK\nlLDPDTfcENqmT58e2qJdSQAuYRaBbXnFZDkmfRYZi8m9rB+7VovsKBRdV8w/3dmFSAQFuxCJoGAX\nIhEU7EIkgoJdiERQsAuRCF2S3sxsPYB9ANoBHHL3Znb84cOH8cEHH0TnYuPktg8YMCDsw+qBLVy4\nMLT95S9/CW1RHTFWE47JMcxWdJukqG7ZM888E/ZZt25daPv6178e2r72ta+FthEjRuS2s+d1wgnx\n5ciuj4aGhtA2ePDg3HYmDbJMP+Y/k1lZFuPIkSNz24cMGVLxWK+88krYpzt09n909ziyhBDHBXob\nL0QidDXYHcAzZvaKmc3pDoeEED1DV9/GX+zum81sOICFZvamuz/X8YDsn8AcABg+fHgXhxNCFKVL\nd3Z335z93gbgUQB/9wVsd5/r7s3u3hx9b1sI0fMUDnYz629mA488BnAFgNe6yzEhRPfSlbfxIwA8\nmkkiJwC4z92fYh0OHz4cFt5jd/2oQCQrrvfyyy+HtsWLF4e2rVu3hrZIPhk1alTYh8knAwcODG0s\no4xleW3cuDG3ncmD69evD22/+c1vQtuuXbtC20033ZTb3tjYGPZh0hWzTZs2LbRF0huTwqIttACe\nvcakVHbOSOrr379/2Gfz5s257d///vfDPoWD3d3XAfhc0f5CiOoi6U2IRFCwC5EICnYhEkHBLkQi\nKNiFSISqFpysq6sLJQgmJ0V9mEzGpDe2xxrbBy7KsrviiivCPhdffHFoa2pqCm1MKmMFM1944YXc\n9uXLl4d9WltbC/nB5jGSqIoW4Dxw4EBoO+uss0LbxIkTQ1uRsZj0VpQoizHKEAWAZ599Nred7Smn\nO7sQiaBgFyIRFOxCJIKCXYhEULALkQhVXY0HeC2xiGhF+M033wz7sOQOlgTBkhnOP//83PZLL700\n7MOSZNhWPQyWTBLVjGOqANtO6tChQ6HtxhtvDG2Rj2yFmY3F6tMxojlmY7EVd1b/j52TKQ1R0tO7\n774b9onqKDJVS3d2IRJBwS5EIijYhUgEBbsQiaBgFyIRFOxCJELVpbcoEYJJXlHCxVtvvRX2YRIE\nk0FYLbzJkyfntrPtglidPCbVsAQUJtlFMs7UqVPDPhdeeGFoO3jwYGhjiTxRMglL1GBbK7GafGyu\nItgcsmSoItIxwK/vaCuqP//5z2GfqAYdu7Z1ZxciERTsQiSCgl2IRFCwC5EICnYhEkHBLkQidCq9\nmdldAL4EYJu7T8zahgK4H8AYAOsBXOPu8V5AHYgyipg0Eck1LCuIyVpMdmHbNQ0aNCi0RTA5iWVX\nsa2hIqmGweZ36NChoY35yPyIstuYNMQkLyopER8j6ZBlr7HXrGimIjvn2rVrc9tffPHFsM+ePXty\n25l/5dzZ7wZw5TFttwBY5O7jASzK/hZCHMd0GuzZfus7j2meCWBe9ngegK90s19CiG6m6Gf2Ee7e\nlj3egtKOrkKI45guL9B56cNI+IHEzOaYWYuZtUSfM4QQPU/RYN9qZk0AkP3eFh3o7nPdvdndm9n3\nzoUQPUvRYF8A4Lrs8XUA/tA97ggheopypLffA5gOoNHMNgH4EYCfAHjAzG4E8A6Aa8odMJIGmDSx\nc+ex64Mldu/eHfZhcgyT5UaMiJcfGhoactuZBMW2amIZYOyc+/btC22DBw/ObS+ardW/f//QxrZy\niiQv1qeo9MZez0hyZNcHk6/Y68KKYrL5X7p0aW77ypUrwz7RNcB87zTY3f3awHRZZ32FEMcP+gad\nEImgYBciERTsQiSCgl2IRFCwC5EIVS046e6hTMIkmSiDiskMTNZiGU8s2yySAJcvXx72WbNmTWhj\nRTGjgo0A3y8tkn9YZtvZZ58d2s4777zQFhXgBIBhw4bltjPJi8lTTNZislxkY9cAg/nfr1+/0Mb2\nHnz22Wdz29k3TiM/2Bzqzi5EIijYhUgEBbsQiaBgFyIRFOxCJIKCXYhEqKr0VldXF2ZRFZFPihYv\nZDYmlUXZSevWrQv7MImnaCYaIxqvra0ttx0AXn/99dC2ePHi0HbllceWJvwb119/fW77qFGjwj5U\nNiKSF7NF1wiTepnMV0QiBoDW1tbQ9uqrr+a2s+u7b9++ue2S3oQQCnYhUkHBLkQiKNiFSAQFuxCJ\nUNXVeCBeLWS1vYokLbAVVTYWW1mP+rEVUDYWS5yIVlsB/tyiBCB2PuZ/lPwDAI899lhoi+r1zZw5\nM+zDVupZnTkGW6kvMhabe5a4smTJktAW1etjq/FjxozJbad1GUOLEOJThYJdiERQsAuRCAp2IRJB\nwS5EIijYhUiEcrZ/ugvAlwBsc/eJWdttAL4F4MjeRre6+xNdcaRIYgKrF8eSEthWU0zmi+QrlljD\ntpOaOHFiaBs+fHhoi7Y0AmL5Z+vWrWGftWvXhrYtW7ZUPBYAzJ8/P7edSVdf/epXQ1tjY2NoY0TX\nFbveGOzaYVLZiSeeGNqia45Jouecc05uO0u4KefOfjeAvPSmX7j7pOynS4EuhOh5Og12d38OQPzN\nCiHEJ4KufGa/2cxWmNldZjak2zwSQvQIRYP91wBOAzAJQBuAn0UHmtkcM2sxsxb2GU8I0bMUCnZ3\n3+ru7e5+GMBvAUwhx85192Z3b66vry/qpxCiixQKdjNr6vDnLACvdY87Qoieohzp7fcApgNoNLNN\nAH4EYLqZTQLgANYD+HY5g9XV1eGkk07Kte3bty/sF0lbTMZhEgnLamKSTCR5nXnmmWGfq666KrR9\n9rOfDW0sW44R+R/V/gP41kT33XdfaItqpwHA22+/ndv+xz/+MexzxhlnhLapU6eGtiJbSjFZi10f\n7LpiEuyMGTNCW1NTU277qlWrwj4nn3xybjvLpOw02N392pzmOzvrJ4Q4vtA36IRIBAW7EImgYBci\nERTsQiSCgl2IRKhqwUl3D4vrsYKIkWxUdJueotsMXXbZZbntU6aE3ynCyJEjC43FJJ729vbQFkl2\nLENw2rRpoY31u+2220Lbhg0bctsjSQ4AVqxYEdqam5tDWxHY3LNrh70u7HpkWXvnn39+bnskyQGx\nVM3kP93ZhUgEBbsQiaBgFyIRFOxCJIKCXYhEULALkQhVl94iWYNJIVEmDyvix4oyMumKFYicPHly\nbjuTSJiMw7KrmI8sQzDqt3fv3rAPs02YMCG0XXLJJaHt4Ycfzm1nBUzYPnvRHnYAl5uiOS6SKdcZ\nLFORvZ6sUGVEJPNRWbniUYQQn0gU7EIkgoJdiERQsAuRCAp2IRKhqqvx7e3t2LVrV74jJIkgWm1l\nddXYyiizDRkSl8CPVAG2qs5qgrGtphhsZTeyse2wDhw4ENpYIszo0aNDW/TcmILCVIbougH4VlnR\nqjtbtWavC5sr1q/Iajy7dpg6EaE7uxCJoGAXIhEU7EIkgoJdiERQsAuRCAp2IRKhnO2fRgO4B8AI\nlLZ7muvuvzSzoQDuBzAGpS2grnH3WB/JiBJDmBw2YMCA3HZW343VCisqkUS2ojXtiiZcRFtosXMy\naZPJckxWLML+/fsL+cH8Z/ULI1mr6BZg7DVj104RqY/5EUmArE85d/ZDAH7g7hMAXADgu2Y2AcAt\nABa5+3gAi7K/hRDHKZ0Gu7u3ufvS7PE+AKsAjAIwE8C87LB5AL7SU04KIbpORZ/ZzWwMgHMBLAEw\nwt3bMtMWlN7mCyGOU8oOdjMbAOBhAN9z96OqHXjpA3Luh2Qzm2NmLWbWwgoXCCF6lrKC3cx6oxTo\n97r7I1nzVjNryuxNALbl9XX3ue7e7O7N9fX13eGzEKIAnQa7lZYR7wSwyt1/3sG0AMB12ePrAPyh\n+90TQnQX5WS9XQTgGwBWmtmyrO1WAD8B8ICZ3QjgHQDXdHYiVoOOyWGRTMIy1Jg8xTKotm/fHtq2\nbct980L9YFlSTI5hUiST84qcb8eOHaGNvS47d+4MbZFUxrLemIRW5DkDsRzGMuzeeeed0DZ48ODQ\nNmzYsIr9YDYmHxeh02B39xcARFdl/uZnQojjDn2DTohEULALkQgKdiESQcEuRCIo2IVIhKoWnARi\nmYFJK5Fc19jYGPZpaGgIbbt37w5tbW1toW3VqlW57azwIpMA2XNmNpYBVmQrISYBbt68ObRt2rQp\ntEUFEVkRxTFjxoS2QYMGhTYma73//vu57Y8//njYZ9GiRaHt8ssvD22zZs0Kbew1i2xFszMjdGcX\nIhEU7EIkgoJdiERQsAuRCAp2IRJBwS5EIlRVenP3QtJQJNewDCpmO3jwYGhjmUaRZMeeEzsfK77I\nZBc2XiRTMskr2ksPANauXRvaVq9eHdqirDImoTHprUhWJABs3bo1t/1Pf/pT2OfVV18NbUxCmzhx\nYmg7++yzQ1skD7Kxhg4dmtvO5kl3diESQcEuRCIo2IVIBAW7EImgYBciEaq6Gl9XV4eBAwdW3C9a\nYWQJKJMmTQpty5cvD20sAWXLli257SxZJNq6CuArpyw5ha0+F0k0Yud74403Qlu00g0Affr0yW0/\n5ZRTwj5sNZ4lfhTZrqno68JW6h944IHQNnv27NAWJXQVfc4RurMLkQgKdiESQcEuRCIo2IVIBAW7\nEImgYBciETqV3sxsNIB7UNqS2QHMdfdfmtltAL4F4Mh+Sbe6+xPsXH369AmlF5aMUQQmC40cOTK0\nRVs8AUBra2tuO5Njxo8fH9qYdMgSeRiRXMOSbp5//vnQxhJG2BxHiRoXXXRR2IfNVRGpCQBGjMjf\nSXzy5Mlhn5aWltDGnvNTTz0V2iLZFgAuuyx/Y6XTTz897BNJm4xydPZDAH7g7kvNbCCAV8xsYWb7\nhbv/Z8WjCiGqTjl7vbUBaMse7zOzVQBG9bRjQojupaLP7GY2BsC5AJZkTTeb2Qozu8vM4q1MhRA1\np+xgN7MBAB4G8D133wvg1wBOAzAJpTv/z4J+c8ysxcxa2FbJQoiepaxgN7PeKAX6ve7+CAC4+1Z3\nb3f3wwB+C2BKXl93n+vuze7ezPYxF0L0LJ0Gu5UyCe4EsMrdf96hvanDYbMAvNb97gkhuotyVuMv\nAvANACvNbFnWdiuAa81sEkpy3HoA3+7sRHV1dejfv3++IwW2x/nggw/CPsOHDw9trB4Yk0gi+WfF\nihVhHyYnRbIQgHCeAJ6ltn379tx2JqE9+OCDoY1t8TR48ODQFklbF154YdiHZaKx58xqCkZ84Qtf\nCG0sK5JtDXXgwIHQ9tJLL4W2t956K7f9jDPOCPtEEjbb2qyc1fgXAOTlCVJNXQhxfKFv0AmRCAp2\nIRJBwS5EIijYhUgEBbsQiVDVgpMMltW0Z8+e3HZWlJEVNoyyjADgvffeC21vvvlmbvuOHTvCPo89\n9lhoY9s4MVlu48aNoW3ZsmW57ex5bdiwIbQxyWvcuHGhbcaMGbntLJOLjVWkyCYQz3FDQ0PY5+qr\nrw5t0VZNAJfXou2wgFjuZd84Xbp0aW773r17wz66swuRCAp2IRJBwS5EIijYhUgEBbsQiaBgFyIR\nqi69RRIKk0+ivbeK7PEFAM3NzaHtww8/DG2RrMEywyLZEAAeffTR0MayAHfu3BnaIv8HDRoU9unX\nr19oYxLmrFmzQls0x0X3sGMZZe4e2iJYptw555wT2m6++ebQxqRIli0XFTllMREVJGWFRXVnFyIR\nFOxCJIKCXYhEULALkQgKdiESQcEuRCJUVXprb28PpYFIXgOAvn37VtyHyTGsH5Plov21nn766bBP\nlIUG8IKZzMYkqkiyY3uDTZ06NbRNnz69UL9o7z4mbbLXjEl2RWB7CzLbWWedFdqi/e0AXnj0xRdf\nzG1n+8pFki7LlNOdXYhEULALkQgKdiESQcEuRCIo2IVIhE5X482sH4DnAPTNjn/I3X9kZmMBzAfQ\nAOAVAN9w94/KOF9uO/vSf7SCy1ZN2Yo1q/1WVxf//xs9enRue1RvDeBJFSyhhSVqROoEADQ2Nua2\nT5gwIexz2mmnhTa2wszqsUVJSmx+2WvG1IQirzVLomKwBCX2upx66qmhLdrwlPkYqVq333572Kec\nO/tBAJe6++dQ2p75SjO7AMBPAfzC3U8HsAvAjWWcSwhRIzoNdi9x5N9I7+zHAVwK4KGsfR6Ar/SI\nh0KIbqHc/dl7ZTu4bgOwEMBaALvd/cj7p00ARvWMi0KI7qCsYHf3dnefBOBkAFMAnFnuAGY2x8xa\nzKyFbScrhOhZKlqNd/fdABYDmApgsJkdWa04GcDmoM9cd29292a2n7cQomfpNNjNbJiZDc4enwjg\ncgCrUAr6I1tnXAfgDz3lpBCi65STCNMEYJ6Z9ULpn8MD7v64mb0BYL6Z/QeAVwHc2dmJ3J0mQkRE\n8gmTY1hSBavTxfyLpJD6+vqwD6vvxqRDJnkNHz48tEVzwiQj5gdLQGHzH80jOx9LUGL9iiQ9sbEY\nTOb76KNYeWZyb5T0VOT6YK9zp8Hu7isAnJvTvg6lz+9CiE8A+gadEImgYBciERTsQiSCgl2IRFCw\nC5EIVmTrnMKDmW0H8E72ZyOAHVUbPEZ+HI38OJpPmh+nuvuwPENVg/2ogc1a3D2u7ig/5If86FY/\n9DZeiERQsAuRCLUM9rk1HLsj8uNo5MfRfGr8qNlndiFEddHbeCESoSbBbmZXmtlqM2s1s1tq4UPm\nx3ozW2lmy8yspYrj3mVm28zstQ5tQ81soZmtyX7nVyHseT9uM7PN2ZwsM7O4mmb3+THazBab2Rtm\n9rqZ/XPWXtU5IX5UdU7MrJ+ZvWxmyzM//j1rH2tmS7K4ud/M4rTDPNy9qj8AeqFU1mocgD4AlgOY\nUG0/Ml/WA2iswbiXADgPwGsd2m4HcEv2+BYAP62RH7cB+Jcqz0cTgPOyxwMBvAVgQrXnhPhR1TkB\nYAAGZI97A1gC4AIADwCYnbXfAeCfKjlvLe7sUwC0uvs6L5Weng9gZg38qBnu/hyAY+tIz0SpcCdQ\npQKegR9Vx93b3H1p9ngfSsVRRqHKc0L8qCpeotuLvNYi2EcB2Njh71oWq3QAz5jZK2Y2p0Y+HGGE\nu7dlj7cAGFFDX242sxXZ2/we/zjRETMbg1L9hCWo4Zwc4wdQ5TnpiSKvqS/QXezu5wG4CsB3zeyS\nWjsElP6zo/SPqBb8GsBpKO0R0AbgZ9Ua2MwGAHgYwPfcfW9HWzXnJMePqs+Jd6HIa0Qtgn0zgI5b\nq4TFKnsad9+c/d4G4FHUtvLOVjNrAoDs97ZaOOHuW7ML7TCA36JKc2JmvVEKsHvd/ZGsuepzkudH\nreYkG7viIq8RtQj2vwIYn60s9gEwG8CCajthZv3NbOCRxwCuAPAa79WjLECpcCdQwwKeR4IrYxaq\nMCdWKjB3J4BV7v7zDqaqzknkR7XnpMeKvFZrhfGY1cYZKK10rgXwwxr5MA4lJWA5gNer6QeA36P0\ndvBjlD573YjSnnmLAKwB8L8AhtbIj/8BsBLACpSCrakKflyM0lv0FQCWZT8zqj0nxI+qzgmAf0Cp\niOsKlP6x/FuHa/ZlAK0AHgTQt5Lz6ht0QiRC6gt0QiSDgl2IRFCwC5EICnYhEkHBLkQiKNiFSAQF\ne4CZjTGzA9n3k4+0VZSaayX+Kzt+hZmdV0afitMYzey6LA10jZldV8bxfbNzt2ZjjSmjz+QsHbg1\ne07xToul4xuydNH9Zvarzs5fLb+yPv+aHb/azL4YHHOvme00s6vz7J9IevoLE5/UHwBjcHTqZ8Wp\nuSh9IeNJlFIWLwCwpIxxK0pjBDAUwLrs95Ds8ZBO+twE4I7s8WwA95fh18vZc7DsOV3VyfH9UfqS\nyncA/KrMOa+GXxOy164vgLHZa9orOPZuAFfX+lrsrh/d2cunSGruTAD3eImXUPpuc1N0cHZXqjSN\n8YsAFrr7TnffhVKG1JVl+HUkdfQhAJexO2Lm8yB3f8lLUXBPZ365+/vu/gKASvbo7nG/sjHmu/tB\nd38bpW+jJbEbsYK9fIqk5lbapwGVpzF2ya9srD3Z2Oz4TRWOUYRq+HU8pVhXFQW7EImgYC+fIqm5\nlfZ5D5WnMXbJr2ys+mxsdvzJFY5RhGr4ddykWFcbBXv5FEnNXQDgm9mq/AUA9vjfKq/8HdnnzkrT\nGJ8GcIWZDckqqFyRtXXm15FV+6sB/F82duRXG4C9ZnZB9hn6m2X4VYRq+LUAwOxs5X8sgPEoLfJ9\n+qn1CuHx+oNjVuOzttzUXAA/BvDlnHMYgP/Ojl8JoLmDbVkwbm4aI4AvA/hx0OeG7PhWANd3aP9d\nxzE7tPfLzt2ajTUua/8MgCeCMZpRSrdcC+BX+NueA98B8J2gz3qUatztR+mz8YTjxK8fZsevRofV\newBPAPhMh7/vxqdoNV4prgGZxvu4u0+ssSuiRpjZ3ShdAw91duwnAb2Nj2kHUN/xSzUiHczsXgDT\nUJl0eFyjO7sQiaA7uxCJoGAXIhEU7EIkgoJdiERQsAuRCP8PoJXHDI2XutsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets display first 2 images with its class below\n",
    "for i in range(0,2):\n",
    "  plt.imshow(X_train[i],cmap='gray')\n",
    "  plt.xlabel(y_train[i])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "zvhLhtGqQHs4",
    "outputId": "603e6984-b086-4a20-b4da-cde2ad987131"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "#lets build the graph\n",
    "tf.keras.backend.clear_session()\n",
    "#initialize the model\n",
    "model = tf.keras.models.Sequential()\n",
    "#lets reshape the input\n",
    "model.add(tf.keras.layers.Reshape((1024,), input_shape=(32,32, )))\n",
    "#lets add first hidden layer\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "#lets add second hidden layer\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "#lets add the third hidden layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "prj-86ziT_pa"
   },
   "outputs": [],
   "source": [
    "#lets add  the output layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rfllrdijU1by"
   },
   "outputs": [],
   "source": [
    "#lets compile the model\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 764
    },
    "colab_type": "code",
    "id": "4ROdGPFtVWBo",
    "outputId": "e44713d1-30a4-4b48-98f7-7940a574566e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 6s 153us/sample - loss: 2.4552 - acc: 0.1008 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 6s 133us/sample - loss: 2.3028 - acc: 0.1009 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 5s 131us/sample - loss: 2.3028 - acc: 0.1006 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 6s 134us/sample - loss: 2.3028 - acc: 0.0985 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 6s 133us/sample - loss: 2.3028 - acc: 0.0997 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 6s 139us/sample - loss: 2.3028 - acc: 0.0999 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 6s 138us/sample - loss: 2.3027 - acc: 0.0987 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 6s 136us/sample - loss: 2.3027 - acc: 0.1014 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 6s 133us/sample - loss: 2.3027 - acc: 0.0996 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 6s 132us/sample - loss: 2.3028 - acc: 0.1005 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 6s 131us/sample - loss: 2.3028 - acc: 0.0991 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 6s 133us/sample - loss: 2.3028 - acc: 0.1012 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 6s 132us/sample - loss: 2.3028 - acc: 0.0997 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 6s 133us/sample - loss: 2.3027 - acc: 0.0985 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 6s 133us/sample - loss: 2.3027 - acc: 0.0992 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 6s 132us/sample - loss: 2.3028 - acc: 0.0991 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 6s 133us/sample - loss: 2.3028 - acc: 0.0989 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 6s 134us/sample - loss: 2.3027 - acc: 0.0999 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 6s 132us/sample - loss: 2.3028 - acc: 0.1011 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 6s 132us/sample - loss: 2.3028 - acc: 0.1015 - val_loss: 2.3026 - val_acc: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f117111e9b0>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets train our model\n",
    "model.fit(X_train,y_train,validation_data=(X_val, y_val), epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B_K2mNA2EwG0"
   },
   "source": [
    "when built model with out batch normalization and with 'relu' activation and 'sgd' optimizer, the loss has remained same through out the epochs which indicates vanishing gradient\n",
    "so lets add momentum and decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fy3bynyKLnbt"
   },
   "outputs": [],
   "source": [
    "#lets build the model with 'sgd' optimizer by adding momentum and decay\n",
    "tf.keras.backend.clear_session()\n",
    "#initialize the model\n",
    "model = tf.keras.models.Sequential()\n",
    "#lets reshape the input\n",
    "model.add(tf.keras.layers.Reshape((1024,), input_shape=(32,32, )))\n",
    "#lets batch normalise the data\n",
    "#model.add(tf.keras.layers.BatchNormalization())\n",
    "#lets add first hidden layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "#lets add second hidden layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "#lets add the third hidden layer\n",
    "model.add(tf.keras.layers.Dense(5, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i9_0AmZML-6n"
   },
   "outputs": [],
   "source": [
    "#lets add  the output layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oAmeWUQvMAyv"
   },
   "outputs": [],
   "source": [
    "#lets compile the model\n",
    "#Create optimizer with default learning rate\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.001, decay=0.001, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 764
    },
    "colab_type": "code",
    "id": "5ia0WLMgMFEA",
    "outputId": "35b78eac-83f6-4168-8202-f66bbba26848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 4s 89us/sample - loss: 2.9055 - acc: 0.0985 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 4s 87us/sample - loss: 2.3026 - acc: 0.1016 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 4s 88us/sample - loss: 2.3026 - acc: 0.1019 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 4s 87us/sample - loss: 2.3026 - acc: 0.1019 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 4s 90us/sample - loss: 2.3026 - acc: 0.1019 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 4s 89us/sample - loss: 2.3026 - acc: 0.1019 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 4s 89us/sample - loss: 2.3026 - acc: 0.1019 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 4s 87us/sample - loss: 2.3026 - acc: 0.1019 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 4s 87us/sample - loss: 2.3026 - acc: 0.1019 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 4s 89us/sample - loss: 2.3026 - acc: 0.1019 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 4s 88us/sample - loss: 2.3026 - acc: 0.1019 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 4s 87us/sample - loss: 2.3026 - acc: 0.1019 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 4s 88us/sample - loss: 2.3026 - acc: 0.1019 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 4s 86us/sample - loss: 2.3026 - acc: 0.1019 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 4s 88us/sample - loss: 2.3026 - acc: 0.1019 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 4s 87us/sample - loss: 2.3026 - acc: 0.1019 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 4s 86us/sample - loss: 2.3026 - acc: 0.1019 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 4s 90us/sample - loss: 2.3026 - acc: 0.1019 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 4s 88us/sample - loss: 2.3026 - acc: 0.1019 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 4s 88us/sample - loss: 2.3026 - acc: 0.1019 - val_loss: 2.3026 - val_acc: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1165f38198>"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets train our model\n",
    "model.fit(X_train,y_train,validation_data=(X_val, y_val), epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__uO4p6rOPG_"
   },
   "source": [
    "even after momentum and decay has added, there is no change in accuracy. lets batch normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dit03jQoM6bk"
   },
   "outputs": [],
   "source": [
    "#lets build the model with batch normalization\n",
    "tf.keras.backend.clear_session()\n",
    "#initialize the model\n",
    "model = tf.keras.models.Sequential()\n",
    "#lets reshape the input\n",
    "model.add(tf.keras.layers.Reshape((1024,), input_shape=(32,32, )))\n",
    "#lets batch normalise the data\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "#lets add first hidden layer\n",
    "model.add(tf.keras.layers.Dense(300, activation='relu'))\n",
    "#lets batch normalise the data\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "#lets add second hidden layer\n",
    "model.add(tf.keras.layers.Dense(200, activation='relu'))\n",
    "#lets batch normalise the data\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "#lets add the third hidden layer\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "#lets add the third hidden layer\n",
    "model.add(tf.keras.layers.Dense(20, activation='relu'))\n",
    "#lets add the third hidden layer\n",
    "model.add(tf.keras.layers.Dense(5, activation='relu'))\n",
    "#lets batch normalise the data\n",
    "model.add(tf.keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QeWMWdemNDkP"
   },
   "outputs": [],
   "source": [
    "#lets add  the output layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q9IWNSMtNGc0"
   },
   "outputs": [],
   "source": [
    "#lets compile the model\n",
    "#Create optimizer with default learning rate\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.002, decay=0.001, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "colab_type": "code",
    "id": "1ma4KW5gs3_n",
    "outputId": "0e9d09ff-35d5-4a12-a0ff-fcebd662d481"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               307500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 105       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                60        \n",
      "=================================================================\n",
      "Total params: 385,051\n",
      "Trainable params: 381,993\n",
      "Non-trainable params: 3,058\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Q4D6Os5dNJ30",
    "outputId": "05b520e5-9601-403d-d467-ad331289b11d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/50\n",
      "42000/42000 [==============================] - 16s 375us/sample - loss: 1.9750 - acc: 0.3002 - val_loss: 1.6447 - val_acc: 0.4523\n",
      "Epoch 2/50\n",
      "42000/42000 [==============================] - 15s 357us/sample - loss: 1.5963 - acc: 0.4681 - val_loss: 1.3215 - val_acc: 0.5811\n",
      "Epoch 3/50\n",
      "42000/42000 [==============================] - 15s 352us/sample - loss: 1.3946 - acc: 0.5459 - val_loss: 1.1433 - val_acc: 0.6434\n",
      "Epoch 4/50\n",
      "42000/42000 [==============================] - 15s 360us/sample - loss: 1.2619 - acc: 0.5923 - val_loss: 1.0597 - val_acc: 0.6803\n",
      "Epoch 5/50\n",
      "42000/42000 [==============================] - 15s 353us/sample - loss: 1.1856 - acc: 0.6208 - val_loss: 0.9733 - val_acc: 0.7088\n",
      "Epoch 6/50\n",
      "42000/42000 [==============================] - 15s 363us/sample - loss: 1.1239 - acc: 0.6389 - val_loss: 0.9133 - val_acc: 0.7278\n",
      "Epoch 7/50\n",
      "42000/42000 [==============================] - 15s 346us/sample - loss: 1.0729 - acc: 0.6594 - val_loss: 0.8687 - val_acc: 0.7428\n",
      "Epoch 8/50\n",
      "42000/42000 [==============================] - 14s 344us/sample - loss: 1.0414 - acc: 0.6693 - val_loss: 0.8355 - val_acc: 0.7520\n",
      "Epoch 9/50\n",
      "42000/42000 [==============================] - 15s 349us/sample - loss: 1.0145 - acc: 0.6764 - val_loss: 0.8048 - val_acc: 0.7625\n",
      "Epoch 10/50\n",
      "42000/42000 [==============================] - 15s 351us/sample - loss: 0.9821 - acc: 0.6868 - val_loss: 0.7801 - val_acc: 0.7692\n",
      "Epoch 11/50\n",
      "42000/42000 [==============================] - 15s 345us/sample - loss: 0.9616 - acc: 0.6968 - val_loss: 0.7641 - val_acc: 0.7735\n",
      "Epoch 12/50\n",
      "42000/42000 [==============================] - 15s 360us/sample - loss: 0.9444 - acc: 0.6991 - val_loss: 0.7454 - val_acc: 0.7792\n",
      "Epoch 13/50\n",
      "42000/42000 [==============================] - 15s 353us/sample - loss: 0.9300 - acc: 0.7051 - val_loss: 0.7347 - val_acc: 0.7814\n",
      "Epoch 14/50\n",
      "42000/42000 [==============================] - 15s 361us/sample - loss: 0.9128 - acc: 0.7120 - val_loss: 0.7215 - val_acc: 0.7852\n",
      "Epoch 15/50\n",
      "42000/42000 [==============================] - 15s 350us/sample - loss: 0.9067 - acc: 0.7126 - val_loss: 0.7090 - val_acc: 0.7912\n",
      "Epoch 16/50\n",
      "42000/42000 [==============================] - 15s 354us/sample - loss: 0.8942 - acc: 0.7155 - val_loss: 0.7007 - val_acc: 0.7915\n",
      "Epoch 17/50\n",
      "42000/42000 [==============================] - 14s 338us/sample - loss: 0.8872 - acc: 0.7170 - val_loss: 0.6931 - val_acc: 0.7944\n",
      "Epoch 18/50\n",
      "42000/42000 [==============================] - 15s 361us/sample - loss: 0.8757 - acc: 0.7218 - val_loss: 0.6872 - val_acc: 0.7966\n",
      "Epoch 19/50\n",
      "42000/42000 [==============================] - 15s 358us/sample - loss: 0.8819 - acc: 0.7187 - val_loss: 0.6735 - val_acc: 0.8016\n",
      "Epoch 20/50\n",
      "42000/42000 [==============================] - 15s 355us/sample - loss: 0.8588 - acc: 0.7280 - val_loss: 0.6652 - val_acc: 0.8041\n",
      "Epoch 21/50\n",
      "42000/42000 [==============================] - 14s 342us/sample - loss: 0.8482 - acc: 0.7307 - val_loss: 0.6608 - val_acc: 0.8045\n",
      "Epoch 22/50\n",
      "42000/42000 [==============================] - 15s 355us/sample - loss: 0.8442 - acc: 0.7314 - val_loss: 0.6550 - val_acc: 0.8068\n",
      "Epoch 23/50\n",
      "42000/42000 [==============================] - 15s 367us/sample - loss: 0.8392 - acc: 0.7326 - val_loss: 0.6454 - val_acc: 0.8104\n",
      "Epoch 24/50\n",
      "42000/42000 [==============================] - 15s 360us/sample - loss: 0.8254 - acc: 0.7378 - val_loss: 0.6434 - val_acc: 0.8097\n",
      "Epoch 25/50\n",
      "42000/42000 [==============================] - 14s 340us/sample - loss: 0.8301 - acc: 0.7364 - val_loss: 0.6414 - val_acc: 0.8110\n",
      "Epoch 26/50\n",
      "42000/42000 [==============================] - 15s 350us/sample - loss: 0.8168 - acc: 0.7436 - val_loss: 0.6309 - val_acc: 0.8142\n",
      "Epoch 27/50\n",
      "42000/42000 [==============================] - 16s 379us/sample - loss: 0.8171 - acc: 0.7424 - val_loss: 0.6280 - val_acc: 0.8164\n",
      "Epoch 28/50\n",
      "42000/42000 [==============================] - 15s 364us/sample - loss: 0.8140 - acc: 0.7391 - val_loss: 0.6231 - val_acc: 0.8158\n",
      "Epoch 29/50\n",
      "42000/42000 [==============================] - 15s 353us/sample - loss: 0.8095 - acc: 0.7451 - val_loss: 0.6213 - val_acc: 0.8169\n",
      "Epoch 30/50\n",
      "42000/42000 [==============================] - 15s 359us/sample - loss: 0.8049 - acc: 0.7437 - val_loss: 0.6148 - val_acc: 0.8184\n",
      "Epoch 31/50\n",
      "42000/42000 [==============================] - 15s 368us/sample - loss: 0.7988 - acc: 0.7454 - val_loss: 0.6141 - val_acc: 0.8184\n",
      "Epoch 32/50\n",
      "42000/42000 [==============================] - 15s 367us/sample - loss: 0.7930 - acc: 0.7469 - val_loss: 0.6097 - val_acc: 0.8197\n",
      "Epoch 33/50\n",
      "42000/42000 [==============================] - 15s 358us/sample - loss: 0.7935 - acc: 0.7490 - val_loss: 0.6045 - val_acc: 0.8224\n",
      "Epoch 34/50\n",
      "42000/42000 [==============================] - 15s 365us/sample - loss: 0.7936 - acc: 0.7453 - val_loss: 0.6028 - val_acc: 0.8217\n",
      "Epoch 35/50\n",
      "42000/42000 [==============================] - 16s 370us/sample - loss: 0.7846 - acc: 0.7503 - val_loss: 0.5998 - val_acc: 0.8238\n",
      "Epoch 36/50\n",
      "42000/42000 [==============================] - 16s 377us/sample - loss: 0.7813 - acc: 0.7500 - val_loss: 0.5949 - val_acc: 0.8239\n",
      "Epoch 37/50\n",
      "42000/42000 [==============================] - 16s 390us/sample - loss: 0.7790 - acc: 0.7556 - val_loss: 0.5923 - val_acc: 0.8249\n",
      "Epoch 38/50\n",
      "42000/42000 [==============================] - 17s 416us/sample - loss: 0.7753 - acc: 0.7524 - val_loss: 0.5903 - val_acc: 0.8259\n",
      "Epoch 39/50\n",
      "42000/42000 [==============================] - 16s 378us/sample - loss: 0.7741 - acc: 0.7567 - val_loss: 0.5880 - val_acc: 0.8266\n",
      "Epoch 40/50\n",
      "42000/42000 [==============================] - 15s 362us/sample - loss: 0.7702 - acc: 0.7533 - val_loss: 0.5827 - val_acc: 0.8281\n",
      "Epoch 41/50\n",
      "42000/42000 [==============================] - 15s 368us/sample - loss: 0.7643 - acc: 0.7594 - val_loss: 0.5808 - val_acc: 0.8286\n",
      "Epoch 42/50\n",
      "42000/42000 [==============================] - 16s 383us/sample - loss: 0.7615 - acc: 0.7591 - val_loss: 0.5792 - val_acc: 0.8295\n",
      "Epoch 43/50\n",
      "42000/42000 [==============================] - 15s 358us/sample - loss: 0.7699 - acc: 0.7568 - val_loss: 0.5800 - val_acc: 0.8294\n",
      "Epoch 44/50\n",
      "42000/42000 [==============================] - 15s 348us/sample - loss: 0.7589 - acc: 0.7576 - val_loss: 0.5793 - val_acc: 0.8295\n",
      "Epoch 45/50\n",
      "42000/42000 [==============================] - 14s 338us/sample - loss: 0.7540 - acc: 0.7612 - val_loss: 0.5736 - val_acc: 0.8304\n",
      "Epoch 46/50\n",
      "42000/42000 [==============================] - 15s 351us/sample - loss: 0.7579 - acc: 0.7602 - val_loss: 0.5724 - val_acc: 0.8319\n",
      "Epoch 47/50\n",
      "42000/42000 [==============================] - 15s 356us/sample - loss: 0.7549 - acc: 0.7603 - val_loss: 0.5722 - val_acc: 0.8314\n",
      "Epoch 48/50\n",
      "42000/42000 [==============================] - 15s 351us/sample - loss: 0.7538 - acc: 0.7596 - val_loss: 0.5694 - val_acc: 0.8323\n",
      "Epoch 49/50\n",
      "42000/42000 [==============================] - 15s 348us/sample - loss: 0.7573 - acc: 0.7590 - val_loss: 0.5637 - val_acc: 0.8348\n",
      "Epoch 50/50\n",
      "42000/42000 [==============================] - 15s 352us/sample - loss: 0.7449 - acc: 0.7634 - val_loss: 0.5678 - val_acc: 0.8342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f115f1480f0>"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets train our model\n",
    "model.fit(X_train,y_train,validation_data=(X_val, y_val), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Vl9uDIkkP6DW",
    "outputId": "c655da34-1c70-404f-c4e1-35564ec5c810"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 1s 68us/sample - loss: 0.7134 - acc: 0.7884\n"
     ]
    }
   ],
   "source": [
    "test_acc = model.evaluate(X_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "a0jpdqd7Qgkw",
    "outputId": "c3cf99ba-46be-4db9-bd54-5f43c0ed9f22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Test accuracy is -  0.78844446\n"
     ]
    }
   ],
   "source": [
    "print('The Test accuracy is - ',test_acc[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ryw05eNgUGhM"
   },
   "source": [
    "batch normalizing the data has improved the accuracy of the model to a large extent . it has overcome the vanishing gradient."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "NeuralNetworks_Project2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
